{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data\\stl10_binary.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33e9a1465f645b1b2050de45f52bf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\stl10_binary.tar.gz to ./data\n",
      "(5000, 3, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "# Loading the training data\n",
    "os.getcwd()\n",
    "path2data=\"./data\"\n",
    "if not os.path.exists(path2data):\n",
    "    os.mkdir(path2data)\n",
    "    \n",
    "data_transformer = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_ds=datasets.STL10(path2data, split='train', \n",
    "                        download=False,transform=data_transformer)\n",
    "\n",
    "print(train_ds.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 500, 5: 500, 6: 500, 3: 500, 9: 500, 7: 500, 4: 500, 8: 500, 0: 500, 2: 500})\n"
     ]
    }
   ],
   "source": [
    "# Count the number of images per category in train_ds\n",
    "import collections\n",
    "\n",
    "y_train=[y for _,y in train_ds]\n",
    "counter_train=collections.Counter(y_train)\n",
    "print(counter_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test dataset\n",
    "test0_ds=datasets.STL10(path2data, split='test', \n",
    "                        download=True,transform=data_transformer)\n",
    "\n",
    "print(test0_ds.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test dataset into two groups\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "indices=list(range(len(test0_ds)))\n",
    "\n",
    "y_test0=[y for _,y in test0_ds]\n",
    "\n",
    "for test_index, val_index in sss.split(indices, y_test0):\n",
    "    print(\"test:\", test_index, \"val:\", val_index)\n",
    "    print(len(val_index),len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the two datasets from test0_ds\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "val_ds=Subset(test0_ds,val_index)\n",
    "test_ds=Subset(test0_ds,test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of images per class in val_ds and test_ds\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "y_test=[y for _,y in test_ds]\n",
    "y_val=[y for _,y in val_ds]\n",
    "\n",
    "counter_test=collections.Counter(y_test)\n",
    "counter_val=collections.Counter(y_val)\n",
    "print(counter_test)\n",
    "print(counter_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages to show sample images\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def show(img,y=None,color=True):\n",
    "    npimg = img.numpy()\n",
    "    npimg_tr=np.transpose(npimg, (1,2,0))\n",
    "    plt.imshow(npimg_tr)\n",
    "    if y is not None:\n",
    "        plt.title(\"label: \"+str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppick random samples\n",
    "grid_size=4\n",
    "rnd_inds=np.random.randint(0,len(train_ds),grid_size)\n",
    "print(\"image indices:\",rnd_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid from random samples\n",
    "x_grid=[train_ds[i][0] for i in rnd_inds]\n",
    "y_grid=[train_ds[i][1] for i in rnd_inds]\n",
    "\n",
    "x_grid=utils.make_grid(x_grid, nrow=4, padding=1)\n",
    "print(x_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call helper function\n",
    "plt.figure(figsize=(10,10))\n",
    "show(x_grid,y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sow samples from val_ds\n",
    "np.random.seed(0)\n",
    "\n",
    "grid_size=4\n",
    "rnd_inds=np.random.randint(0,len(val_ds),grid_size)\n",
    "print(\"image indices:\",rnd_inds)\n",
    "\n",
    "x_grid=[val_ds[i][0] for i in rnd_inds]\n",
    "y_grid=[val_ds[i][1] for i in rnd_inds]\n",
    "\n",
    "x_grid=utils.make_grid(x_grid, nrow=4, padding=2)\n",
    "print(x_grid.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "show(x_grid,y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and standard deviation from train_ds\n",
    "import numpy as np\n",
    "\n",
    "meanRGB=[np.mean(x.numpy(),axis=(1,2)) for x,_ in train_ds]\n",
    "stdRGB=[np.std(x.numpy(),axis=(1,2)) for x,_ in train_ds]\n",
    "\n",
    "meanR=np.mean([m[0] for m in meanRGB])\n",
    "meanG=np.mean([m[1] for m in meanRGB])\n",
    "meanB=np.mean([m[2] for m in meanRGB])\n",
    "\n",
    "stdR=np.mean([s[0] for s in stdRGB])\n",
    "stdG=np.mean([s[1] for s in stdRGB])\n",
    "stdB=np.mean([s[2] for s in stdRGB])\n",
    "\n",
    "print(meanR,meanG,meanB)\n",
    "print(stdR,stdG,stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformers\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  \n",
    "    transforms.RandomVerticalFlip(p=0.5),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])])\n",
    "                 \n",
    "\n",
    "test0_transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB]),\n",
    "    ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.transform=train_transformer\n",
    "test0_ds.transform=test0_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will display the transformed sample images from train_ds:\n",
    "import torch\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "grid_size=4\n",
    "rnd_inds=np.random.randint(0,len(train_ds),grid_size)\n",
    "print(\"image indices:\",rnd_inds)\n",
    "\n",
    "x_grid=[train_ds[i][0] for i in rnd_inds]\n",
    "y_grid=[train_ds[i][1] for i in rnd_inds]\n",
    "\n",
    "x_grid=utils.make_grid(x_grid, nrow=4, padding=2)\n",
    "print(x_grid.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "show(x_grid,y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create dataloaders from train_ds and val_ds\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=64, shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then get a batch of data from train_dl:\n",
    "for x, y in train_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a batch from validation data\n",
    "for x, y in val_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "model_resnet18 = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "num_classes=10\n",
    "num_ftrs = model_resnet18.fc.in_features \n",
    "model_resnet18.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model_resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in model_resnet18.parameters():\n",
    "    w=w.data.cpu()\n",
    "    print(w.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_w=torch.min(w)\n",
    "w1 = (-1/(2*min_w))*w + 0.5 \n",
    "print(torch.min(w1).item(),torch.max(w1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=len(w1)\n",
    "x_grid=[w1[i] for i in range(grid_size)]\n",
    "x_grid=utils.make_grid(x_grid, nrow=8, padding=1)\n",
    "print(x_grid.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "show(x_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "resnet18_pretrained = models.resnet18(pretrained=True)\n",
    "\n",
    "num_classes=10\n",
    "num_ftrs = resnet18_pretrained.fc.in_features\n",
    "resnet18_pretrained.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "resnet18_pretrained.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=len(w1)\n",
    "x_grid=[w1[i] for i in range(grid_size)]\n",
    "x_grid=utils.make_grid(x_grid, nrow=8, padding=1)\n",
    "print(x_grid.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "show(x_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more pre-trained model oppportunities\n",
    "num_classes=10\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "# change the last layer\n",
    "vgg19.classifier[6] = nn.Linear(4096,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# los function defined\n",
    "#The resnet18 model uses linear outputs. \n",
    "#Thus, we use nn.CrossEntropyLoss as the loss function. \n",
    "#An important argument in defining the loss function to pay attention to is reduction, \n",
    "#which specifies the reduction to apply to the output.\n",
    "#There are three options to choose from: none, sum, and mean.\n",
    "#We choose reduction=\"sum\" so the output loss will be summed. \n",
    "#Since we will process the data in batches, this will return the sum of loss values per batch of data.\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "n,c=4,5\n",
    "y = torch.randn(n, c, requires_grad=True)\n",
    "print(y.shape)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "target = torch.randint(c,size=(n,))\n",
    "print(target.shape)\n",
    "\n",
    "loss = loss_func(y, target)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "print (y.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "opt = optim.Adam(model_resnet18.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "current_lr=get_lr(opt)\n",
    "print('current lr={}'.format(current_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "lr_scheduler = CosineAnnealingLR(opt,T_max=2,eta_min=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    lr_scheduler.step()\n",
    "    print(\"epoch %s, lr: %.1e\" %(i,get_lr(opt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, develop a helper function to count the number of correct predictions per data batch:\n",
    "def metrics_batch(output, target):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "    corrects=pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then develop a helper function to compute the loss value per batch of data:\n",
    "def loss_batch(loss_func, output, target, opt=None):  \n",
    "    loss = loss_func(output, target)   \n",
    "    metric_b = metrics_batch(output,target)\n",
    "    \n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start the helper function by initializing variables:\n",
    "def loss_epoch(model,loss_func,dataset_dl,sanity_check=False,opt=None):\n",
    "    running_loss=0.0\n",
    "    running_metric=0.0\n",
    "    len_data=len(dataset_dl.dataset)\n",
    "    \n",
    "    for xb, yb in dataset_dl:\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        output=model(xb)\n",
    "        loss_b,metric_b=loss_batch(loss_func, output, yb, opt)\n",
    "        running_loss+=loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric+=metric_b\n",
    "\n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "loss=running_loss/float(len_data)\n",
    "metric=running_metric/float(len_data)\n",
    "return loss, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(model, params):\n",
    "    num_epochs=params[\"num_epochs\"]\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "     loss_history={\n",
    "        \"train\": [],\n",
    "        \"val\": [],\n",
    "    }\n",
    "    \n",
    "    metric_history={\n",
    "        \"train\": [],\n",
    "        \"val\": [],\n",
    "    }\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss=float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr=get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs - 1, current_lr))\n",
    "        \n",
    "        model.train()\n",
    "        train_loss, train_metric=loss_epoch(model,loss_func,train_dl,sanity_check,opt)\n",
    "\n",
    "        loss_history[\"train\"].append(train_loss)\n",
    "        metric_history[\"train\"].append(train_metric)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric=loss_epoch(model,loss_func,val_dl,sanity_check)\n",
    "                      \n",
    "        loss_history[\"val\"].append(val_loss)\n",
    "        metric_history[\"val\"].append(val_metric)\n",
    "        \n",
    "         if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print(\"Copied best model weights!\")\n",
    "            \n",
    "             lr_scheduler.step()\n",
    "\n",
    "            print(\"train loss: %.6f, dev loss: %.6f, accuracy: %.2f\" %(train_loss,val_loss,100*val_metric))\n",
    "            print(\"-\"*10) \n",
    "            \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "opt = optim.Adam(model_resnet18.parameters(), lr=1e-4)\n",
    "lr_scheduler = CosineAnnealingLR(opt,T_max=5,eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "params_train={\n",
    " \"num_epochs\": 100,\n",
    " \"optimizer\": opt,\n",
    " \"loss_func\": loss_func,\n",
    " \"train_dl\": train_dl,\n",
    " \"val_dl\": val_dl,\n",
    " \"sanity_check\": False,\n",
    " \"lr_scheduler\": lr_scheduler,\n",
    " \"path2weights\": \"./models/resnet18.pt\",\n",
    "}\n",
    "\n",
    "model_resnet18,loss_hist,metric_hist=train_val(model_resnet18,params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=params_train[\"num_epochs\"]\n",
    "\n",
    "plt.title(\"Train-Val Loss\")\n",
    "plt.plot(range(1,num_epochs+1),loss_hist[\"train\"],label=\"train\")\n",
    "plt.plot(range(1,num_epochs+1),loss_hist[\"val\"],label=\"val\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Train-Val Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),metric_hist[\"train\"],label=\"train\")\n",
    "plt.plot(range(1,num_epochs+1),metric_hist[\"val\"],label=\"val\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "opt = optim.Adam(resnet18_pretrained.parameters(), lr=1e-4)\n",
    "lr_scheduler = CosineAnnealingLR(opt,T_max=5,eta_min=1e-6)\n",
    "\n",
    "params_train={\n",
    " \"num_epochs\": 100,\n",
    " \"optimizer\": opt,\n",
    " \"loss_func\": loss_func,\n",
    " \"train_dl\": train_dl,\n",
    " \"val_dl\": val_dl,\n",
    " \"sanity_check\": False,\n",
    " \"lr_scheduler\": lr_scheduler,\n",
    " \"path2weights\": \"./models/resnet18_pretrained.pt\",\n",
    "}\n",
    "\n",
    "resnet18_pretrained,loss_hist,metric_hist=train_val(resnet18_pretrained,params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=params_train[\"num_epochs\"]\n",
    "\n",
    "plt.title(\"Train-Val Loss\")\n",
    "plt.plot(range(1,num_epochs+1),loss_hist[\"train\"],label=\"train\")\n",
    "plt.plot(range(1,num_epochs+1),loss_hist[\"val\"],label=\"val\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Train-Val Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),metric_hist[\"train\"],label=\"train\")\n",
    "plt.plot(range(1,num_epochs+1),metric_hist[\"val\"],label=\"val\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "model_resnet18 = models.resnet18(pretrained=False)\n",
    "num_ftrs = model_resnet18.fc.in_features\n",
    "num_classes=10\n",
    "model_resnet18.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "path2weights=\"./models/resnet18_pretrained.pt\"\n",
    "model_resnet18.load_state_dict(torch.load(path2weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    model_resnet18=model_resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model(model,dataset,device, num_classes=10,sanity_check=False):\n",
    "\n",
    "    len_data=len(dataset)\n",
    "    y_out=torch.zeros(len_data,num_classes)\n",
    "    y_gt=np.zeros((len_data),dtype=\"uint8\")\n",
    "    model=model.to(device)\n",
    "    elapsed_time=[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len_data):\n",
    "            x,y=dataset[i]\n",
    "            y_gt[i]=y\n",
    "            start=time.time()    \n",
    "            yy=model(x.unsqueeze(0).to(device))\n",
    "            y_out[i]=torch.softmax(yy,dim=1)\n",
    "            elapsed=time.time()-start\n",
    "            elapsed_times.append(elapsed)\n",
    "\n",
    "            if sanity_check is True:\n",
    "                break\n",
    "    inference_time=np.mean(elapsed_times)*1000\n",
    "    print(\"average inference time per image on %s: %.2f ms \" %(device,inference_time))\n",
    "    return y_out.numpy(),y_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "y_out,y_gt=deploy_model(cnn_model,val_ds,device=device,sanity_check=False)\n",
    "print(y_out.shape,y_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = np.argmax(y_out,axis=1)\n",
    "print(y_pred.shape,y_gt.shape)\n",
    "\n",
    "acc=accuracy_score(y_pred,y_gt)\n",
    "print(\"accuracy: %.2f\" %acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out,y_gt=deploy_model(model_resnet18,test_ds,device=device)\n",
    "\n",
    "y_pred = np.argmax(y_out,axis=1)\n",
    "acc=accuracy_score(y_pred,y_gt)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    mean=[0.4467106, 0.43980986, 0.40664646]\n",
    "    std=[0.22414584,0.22148906,0.22389975]\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array(mean)\n",
    "    std = np.array(std)\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=4\n",
    "rnd_inds=np.random.randint(0,len(test_ds),grid_size)\n",
    "print(\"image indices:\",rnd_inds)\n",
    "\n",
    "x_grid_test=[test_ds[i][0] for i in rnd_inds]\n",
    "y_grid_test=[(y_pred[i],y_gt[i]) for i in rnd_inds]\n",
    "\n",
    "x_grid_test=utils.make_grid(x_grid_test, nrow=4, padding=2)\n",
    "print(x_grid_test.shape)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "imshow(x_grid_test,y_grid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cpu = torch.device(\"cpu\")\n",
    "y_out,y_gt=deploy_model(model_resnet18,val_ds,device=device_cpu,sanity_check=False)\n",
    "print(y_out.shape,y_gt.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
